{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "import numpy, random, math\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "\"\"\"\n",
    "TO DO LIST:\n",
    "Create a SVM classifier. Use transformation into higher dimension\n",
    "in order to separate data and to create an indicator function ind(s).\n",
    "Use dual formulation, kernel functions and slack variables.\n",
    "\n",
    "DONE 1. Define a suitable kernel function (a function which takes two data points as arguments and returns a scalar value)'\n",
    "   Start with the linear kernel function but explore all of the function in lab instruction section 3.3\n",
    "DONE 2. Define objective (a function which takes the α-vector as argument and returns a scalar value) \n",
    "   This function should effectively implement equation 4 in the lab instructions. NOTE THAT THIS FUNCTION WILL BE CALLED\n",
    "   SEVERAL HUNDRED TIMES, SO MAKE IT EFFICIENT. Define P as a global numpy array\n",
    "DONE 3. Define zerofun (zerofun is a function you have defined which calculates the value which\n",
    "   should be constrained to zero. Like objective, zerofun takes a vector as\n",
    "   argument and returns a scalar value. \n",
    "DONE 4. Define a function that creates the matrix P from the data points  \n",
    "DONE 5. Call minimize\n",
    "DONE 6. Extrac the non-zero α values (use 10^-5 as the limit). Save non zero α values with the corresponding data points xi and\n",
    "   target values ti in a separate data structure, for example a list.\n",
    "7. Calculate b (the bias) using equation 7 in lab instruction\n",
    "8. Implement the indicator function ind(s). ((equation 6) which uses the non-zero α values together with the corresponding\n",
    "   xi and ti to classify new points.\n",
    "9. Generate test data according to the lab instructions section 5\n",
    "10. Plot the data and the decision boundary according to section 6\n",
    "11. After completing above tasks with the linear kernel function, move on to questions under section 7.\n",
    "\"\"\" "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nTO DO LIST:\\nCreate a SVM classifier. Use transformation into higher dimension\\nin order to separate data and to create an indicator function ind(s).\\nUse dual formulation, kernel functions and slack variables.\\n\\nDONE 1. Define a suitable kernel function (a function which takes two data points as arguments and returns a scalar value)'\\n   Start with the linear kernel function but explore all of the function in lab instruction section 3.3\\nDONE 2. Define objective (a function which takes the α-vector as argument and returns a scalar value) \\n   This function should effectively implement equation 4 in the lab instructions. NOTE THAT THIS FUNCTION WILL BE CALLED\\n   SEVERAL HUNDRED TIMES, SO MAKE IT EFFICIENT. Define P as a global numpy array\\nDONE 3. Define zerofun (zerofun is a function you have defined which calculates the value which\\n   should be constrained to zero. Like objective, zerofun takes a vector as\\n   argument and returns a scalar value. \\nDONE 4. Define a function that creates the matrix P from the data points  \\nDONE 5. Call minimize\\nDONE 6. Extrac the non-zero α values (use 10^-5 as the limit). Save non zero α values with the corresponding data points xi and\\n   target values ti in a separate data structure, for example a list.\\n7. Calculate b (the bias) using equation 7 in lab instruction\\n8. Implement the indicator function ind(s). ((equation 6) which uses the non-zero α values together with the corresponding\\n   xi and ti to classify new points.\\n9. Generate test data according to the lab instructions section 5\\n10. Plot the data and the decision boundary according to section 6\\n11. After completing above tasks with the linear kernel function, move on to questions under section 7.\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "def kernel(x, y):\n",
    "    if (kernel_func == \"linear\"):\n",
    "        scalar = numpy.dot(x, y)\n",
    "    elif (kernel_func == \"poly\"):\n",
    "        scalar = (numpy.dot(x, y) + 1) ** p\n",
    "    elif(kernel_func == \"rbf\"):\n",
    "        scalar = math.exp(-(numpy.linalg.norm(x-y) ** 2) / (2 * sigma ** 2))\n",
    "    return scalar\n",
    "\n",
    "def make_matrix(targets, inputs):\n",
    "    # global P\n",
    "    P = []\n",
    "    for i in range(len(targets)):\n",
    "        P.append([targets[i]*targets[j]*kernel(inputs[i], inputs[j]) for j in range(len(targets))])\n",
    "    return P\n",
    "\n",
    "## Implementing equation 4\n",
    "## Should return a scalar\n",
    "def objective(vector_alpha):\n",
    "    scalar = 0.5 * numpy.sum(numpy.multiply(numpy.outer(vector_alpha, vector_alpha), P)) - numpy.sum(vector_alpha)\n",
    "    return scalar\n",
    "\n",
    "def zerofun(vector_alpha):\n",
    "    scalar = numpy.dot(vector_alpha, targets)\n",
    "    return scalar\n",
    "    \n",
    "def calculate_bias(low_threshold, C, alpha):\n",
    "    non_zero_index = [i for i in range(len(alpha)) if alpha[i] > low_threshold]\n",
    "\n",
    "    ## Chosse margin point aka Suport Vector\n",
    "    if C != None:\n",
    "        for i in range(len(non_zero_index)):\n",
    "            if alpha[non_zero_index[i]] < C:\n",
    "                margin_point_index = non_zero_index[i]\n",
    "                break\n",
    "    else:\n",
    "        margin_point_index = non_zero_index[0]\n",
    "\n",
    "    b = sum([alpha[i] * targets[i] * kernel(inputs[margin_point_index],inputs[i]) for i in range(len(alpha))]) - targets[margin_point_index]\n",
    "    return b\n",
    "\n",
    "def indicator(x, y):\n",
    "    return sum([alpha[i] * targets[i] * kernel([x, y], inputs[i]) for i in range(len(alpha))]) - b\n",
    "\n",
    "def genData():\n",
    "    numpy.random.seed(100) # TODO: Comment out\n",
    "    classA = numpy.concatenate((numpy.random.randn(10, 2) * 0.2 + [1.5, 0.5], numpy.random.randn(10, 2) * 0.2 + [-1.5, 0.5]))\n",
    "    classB = numpy.random.randn(20, 2) * 0.2 + [0.0 , -0.5]\n",
    "    inputs = numpy.concatenate((classA , classB))\n",
    "    targets = numpy.concatenate((numpy.ones(classA.shape[0]), -numpy.ones(classB.shape[0])))\n",
    "    N = inputs.shape[0] # Number of rows (samples)\n",
    "    permute = list(range(N)) \n",
    "    random.shuffle(permute)\n",
    "    inputs = inputs[permute, :]\n",
    "    targets = targets[permute]\n",
    "    return targets, inputs, classA, classB, N\n",
    "\n",
    "def do_my_plot(classA, classB):\n",
    "    plt.plot([p[0] for p in classA], [p[1] for p in classA], 'b.')\n",
    "    plt.plot([p[0] for p in classB], [p[1] for p in classB], 'r.')\n",
    "    plt.axis('equal')\n",
    "\n",
    "    xgrid= numpy.linspace(5,5)\n",
    "    ygrid = numpy.linspace(4,4)\n",
    "    grid = numpy.array([[indicator(x,y) for x in xgrid] for y in ygrid])\n",
    "    plt.contour(xgrid,ygrid,grid,(1.0,0.0,1.0), colors = ('red', 'black', 'blue'), linewidths=(1,3,1))\n",
    "\n",
    "\n",
    "\n",
    "    plt.savefig('svmplot.pdf')\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "def main():\n",
    "    global targets, inputs, N, classA, classB, b, kernel_func, p, sigma, alpha\n",
    "\n",
    "    ## Step 1 initialize global variables\n",
    "    kernel_func = 'linear'\n",
    "    p = 1\n",
    "    sigma = 1\n",
    "    targets, inputs, classA, classB, N = genData()\n",
    "    P = make_matrix(targets, inputs)\n",
    "\n",
    "    # Easy plot TODO: Remove?\n",
    "    # do_my_plot(classA, classB)\n",
    "    \n",
    "\n",
    "    # Step 2 call minimize\n",
    "    C = None\n",
    "    B = [(0,C) for b in range(N)] #list of pairs stating the lower and upper bounds. same length as alpha.\n",
    "    XC={'type':'eq', 'fun':zerofun}\n",
    "    start = numpy.zeros(N) # N = number of training samples\n",
    "    ret = minimize(objective, start, bounds=B, constraints=XC) #TODO: how minimize works\n",
    "    alpha = ret['x']\n",
    "    print(ret['success'])\n",
    "    print(ret['message'])\n",
    "\n",
    "    #Step 3 Calculate bias\n",
    "    b = calculate_bias(10**(-5), C, alpha)\n",
    "    print(b)\n",
    "    #Step 4 Plot\n",
    "    do_my_plot(classA, classB)\n",
    "\n",
    "\n",
    "\n",
    "    # Save non-zeros\n",
    "    # non_zero_index = [i for i in range(len(alpha)) if alpha[i] > 10**(-5)]\n",
    "    # non_zero_alpha = [alpha[i] for i in non_zero_index]\n",
    "    # non_zero_data_points = [inputs[i] for i in non_zero_index]\n",
    "    # non_zero_target_values = [targets[i] for i in non_zero_index]\n",
    "    \n",
    "\n",
    "    # print(non_zero_index)\n",
    "    # print(non_zero_alpha)\n",
    "    # print(non_zero_data_points)\n",
    "    # print(non_zero_target_values)\n",
    "\n",
    "\n",
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "Optimization terminated successfully\n",
      "-1.4474411394462385\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/31/jfz2198521qchs_6wjw0cyyr0000gn/T/ipykernel_36648/2267429604.py:66: UserWarning: No contour levels were found within the data range.\n",
      "  plt.contour(xgrid,ygrid,grid,(1.0,0.0,1.0), colors = ('red', 'black', 'blue'), linewidths=(1,3,1))\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}